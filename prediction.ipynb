{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "Unsloth: Your Flash Attention 2 installation seems to be broken?\n",
      "A possible explanation is you have a new CUDA version which isn't\n",
      "yet compatible with FA2? Please file a ticket to Unsloth or FA2.\n",
      "We shall now use Xformers instead, which does not have any performance hits!\n",
      "We found this negligible impact by benchmarking on 1x A100.\n",
      "ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import torch\n",
    "import wandb\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from unsloth import FastVisionModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ CONFIG â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "MODEL_PATH  = \"/teamspace/studios/this_studio/qwen2vl_amazon_lora\"\n",
    "VAL_CSV     = \"/teamspace/studios/this_studio/small_val.csv\"\n",
    "IMAGE_DIR   = \"/teamspace/studios/this_studio/images/\"\n",
    "OUTPUT_CSV  = \"/teamspace/studios/this_studio/val_predictions.csv\"\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ALLOWED_UNITS = {\n",
    "    \"centimetre\", \"foot\", \"inch\", \"metre\", \"millimetre\", \"yard\",\n",
    "    \"cubic foot\", \"cubic inch\", \"cup\", \"decilitre\", \"fluid ounce\",\n",
    "    \"gallon\", \"imperial gallon\", \"litre\", \"microlitre\", \"millilitre\",\n",
    "    \"pint\", \"quart\", \"gram\", \"kilogram\", \"microgram\", \"milligram\",\n",
    "    \"ounce\", \"pound\", \"ton\", \"kilovolt\", \"millivolt\", \"volt\",\n",
    "    \"kilowatt\", \"watt\", \"decibel\", \"centilitre\", \"cubic centimetre\", \"tonne\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess(raw: str) -> str:\n",
    "    raw = raw.strip()\n",
    "    if raw.upper() in [\"NA\", \"N/A\", \"NONE\", \"NOT FOUND\", \"\"]:\n",
    "        return \"\"\n",
    "    pattern = re.compile(r'(-?\\d+(?:\\.\\d+)?)\\s+([a-zA-Z\\s]+)')\n",
    "    match = pattern.search(raw)\n",
    "    if not match:\n",
    "        return \"\"\n",
    "    number = match.group(1)\n",
    "    unit   = match.group(2).strip().lower()\n",
    "    if unit.replace('ter', 'tre') in ALLOWED_UNITS:\n",
    "        unit = unit.replace('ter', 'tre')\n",
    "    if unit.replace('feet', 'foot') in ALLOWED_UNITS:\n",
    "        unit = unit.replace('feet', 'foot')\n",
    "    if unit not in ALLOWED_UNITS:\n",
    "        return \"\"\n",
    "    try:\n",
    "        return f\"{float(number)} {unit}\"\n",
    "    except:\n",
    "        return \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_f1(predictions, ground_truths):\n",
    "    tp, fp, fn = 0, 0, 0\n",
    "    for pred, gt in zip(predictions, ground_truths):\n",
    "        pred, gt = str(pred).strip(), str(gt).strip()\n",
    "        if pred != \"\" and gt != \"\" and pred == gt:\n",
    "            tp += 1\n",
    "        elif pred != \"\" and gt != \"\" and pred != gt:\n",
    "            fp += 1\n",
    "        elif pred != \"\" and gt == \"\":\n",
    "            fp += 1\n",
    "        elif pred == \"\" and gt != \"\":\n",
    "            fn += 1\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
    "    recall    = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "    f1        = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0.0\n",
    "    return {\"f1\": f1, \"precision\": precision, \"recall\": recall, \"tp\": tp, \"fp\": fp, \"fn\": fn}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(entity_name):\n",
    "    units_str = \", \".join(sorted(ALLOWED_UNITS))\n",
    "    return (\n",
    "        f\"What is the {entity_name}? \"\n",
    "        f\"Reply with only the value and unit from: {units_str}. \"\n",
    "        f\"If not visible, reply with empty string.\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...\n",
      "==((====))==  Unsloth 2026.2.1: Fast Qwen2_Vl patching. Transformers: 5.3.0.dev0.\n",
      "   \\\\   /|    NVIDIA L4. Num GPUs = 1. Max memory: 22.278 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.10.0+cu128. CUDA: 8.9. CUDA Toolkit: 12.8. Triton: 3.6.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.35. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dda1b0057c104081ae7b46adedbe2ecd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/729 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The image processor of type `Qwen2VLImageProcessor` is now loaded as a fast processor by default, even if the model checkpoint was saved with a slow processor. This is a breaking change and may produce slightly different outputs. To continue using the slow processor, instantiate this class with `use_fast=False`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val samples: 1996\n"
     ]
    }
   ],
   "source": [
    "# Load model\n",
    "print(\"Loading model...\")\n",
    "model, processor = FastVisionModel.from_pretrained(\n",
    "    MODEL_PATH,\n",
    "    load_in_4bit=True,\n",
    ")\n",
    "FastVisionModel.for_inference(model)\n",
    "model.eval()\n",
    "device = next(model.parameters()).device\n",
    "\n",
    "# Load val data\n",
    "val_df = pd.read_csv(VAL_CSV)\n",
    "print(f\"Val samples: {len(val_df)}\")\n",
    "\n",
    "predictions, ground_truths = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Verify GPU\n",
    "print(next(model.parameters()).device)  # must show cuda:0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1996/1996 [1:20:42<00:00,  2.43s/it]\n"
     ]
    }
   ],
   "source": [
    "for _, row in tqdm(val_df.iterrows(), total=len(val_df)):\n",
    "    image_path = f\"{IMAGE_DIR}{Path(row['image_link']).name}\"\n",
    "    gt = str(row[\"entity_value\"]).strip()\n",
    "\n",
    "    if not os.path.exists(image_path):\n",
    "        predictions.append(\"\")\n",
    "        ground_truths.append(gt)\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "    except:\n",
    "        predictions.append(\"\")\n",
    "        ground_truths.append(gt)\n",
    "        continue\n",
    "\n",
    "    messages = [{\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"image\"},\n",
    "            {\"type\": \"text\", \"text\": build_prompt(row[\"entity_name\"])},\n",
    "        ],\n",
    "    }]\n",
    "\n",
    "    text_prompt = processor.apply_chat_template(\n",
    "        messages, tokenize=False, add_generation_prompt=True\n",
    "    )\n",
    "    inputs = processor(\n",
    "        text=[text_prompt], images=[image],\n",
    "        return_tensors=\"pt\", padding=True\n",
    "    ).to(device)\n",
    "    with torch.inference_mode():  # faster than torch.no_grad()\n",
    "        output_ids = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=16,   # â† reduce from 32, entity values are short\n",
    "            do_sample=False,\n",
    "            use_cache=True,\n",
    "        )\n",
    "    generated = output_ids[0][inputs[\"input_ids\"].shape[1]:]\n",
    "    raw = processor.decode(generated, skip_special_tokens=True).strip()\n",
    "    predictions.append(postprocess(raw))\n",
    "    ground_truths.append(gt)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "VAL SET RESULTS\n",
      "==================================================\n",
      "  F1 Score:  0.7387\n",
      "  Precision: 0.6466\n",
      "  Recall:    0.8615\n",
      "  TP: 1169  FP: 639  FN: 188\n",
      "\n",
      "Per-entity F1:\n",
      "  depth                           F1: 0.7201\n",
      "  height                          F1: 0.7950\n",
      "  item_volume                     F1: 0.7333\n",
      "  item_weight                     F1: 0.7552\n",
      "  maximum_weight_recommendation   F1: 0.3571\n",
      "  voltage                         F1: 0.7500\n",
      "  wattage                         F1: 0.8846\n",
      "  width                           F1: 0.6421\n",
      "\n",
      "Saved to /teamspace/studios/this_studio/val_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "# Compute F1\n",
    "metrics = compute_f1(predictions, ground_truths)\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"VAL SET RESULTS\")\n",
    "print(\"=\"*50)\n",
    "print(f\"  F1 Score:  {metrics['f1']:.4f}\")\n",
    "print(f\"  Precision: {metrics['precision']:.4f}\")\n",
    "print(f\"  Recall:    {metrics['recall']:.4f}\")\n",
    "print(f\"  TP: {metrics['tp']}  FP: {metrics['fp']}  FN: {metrics['fn']}\")\n",
    "\n",
    "# Per entity breakdown\n",
    "print(\"\\nPer-entity F1:\")\n",
    "for entity in val_df[\"entity_name\"].unique():\n",
    "    mask  = val_df[\"entity_name\"] == entity\n",
    "    idxs  = val_df[mask].index.tolist()\n",
    "    e_p   = [predictions[i] for i in range(len(val_df)) if val_df.iloc[i].name in idxs]\n",
    "    e_g   = [ground_truths[i] for i in range(len(val_df)) if val_df.iloc[i].name in idxs]\n",
    "    e_m   = compute_f1(e_p, e_g)\n",
    "    print(f\"  {entity:30s}  F1: {e_m['f1']:.4f}\")\n",
    "\n",
    "# Save predictions\n",
    "val_df[\"prediction\"] = predictions\n",
    "val_df.to_csv(OUTPUT_CSV, index=False)\n",
    "print(f\"\\nSaved to {OUTPUT_CSV}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
